{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lyon/.pyenv/versions/3.6.4/envs/scikit-learn/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-197b1c0b835b>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/lyon/.pyenv/versions/3.6.4/envs/scikit-learn/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/lyon/.pyenv/versions/3.6.4/envs/scikit-learn/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/lyon/.pyenv/versions/3.6.4/envs/scikit-learn/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/lyon/.pyenv/versions/3.6.4/envs/scikit-learn/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/lyon/.pyenv/versions/3.6.4/envs/scikit-learn/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "import tensorflow as tf\n",
    "\n",
    "mnist = read_data_sets('MNIST_data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    with tf.name_scope('weights'):\n",
    "        initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "        weight = tf.Variable(initial, name='W')\n",
    "        \n",
    "    return weight\n",
    "\n",
    "def bias_variable(shape):\n",
    "    with tf.name_scope('biases'):\n",
    "        initial = tf.constant(0.1, shape=shape)\n",
    "        biases = tf.Variable(initial, name='b')\n",
    "        \n",
    "    return biases\n",
    "\n",
    "def add_fc_layer(x, in_size, out_size, activation_function=None):\n",
    "    with tf.name_scope('fc_layer'):\n",
    "        Weights = weight_variable([in_size, out_size])\n",
    "        biases = bias_variable([1, out_size])\n",
    "            \n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            Wx_plus_b = tf.add(tf.matmul(x, Weights), biases)\n",
    "            \n",
    "        if activation_function is None:\n",
    "            outputs = Wx_plus_b\n",
    "        else:\n",
    "            outputs = activation_function(Wx_plus_b, )\n",
    "    \n",
    "    tf.summary.histogram('weights', Weights)\n",
    "    tf.summary.histogram('biases', biases)\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "def add_conv_layer(x, kernel_shape, color_channel, kernel_num):\n",
    "    with tf.name_scope('conv'):\n",
    "        W_conv = weight_variable(kernel_shape+[color_channel, kernel_num])\n",
    "        b_conv = bias_variable([kernel_num])\n",
    "        \n",
    "        h_conv = tf.nn.relu(tf.nn.conv2d(x, W_conv, strides=[1, 1, 1, 1], padding='SAME'))\n",
    "        \n",
    "        h_pool = tf.nn.max_pool(h_conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        \n",
    "        tf.summary.histogram('W_conv', W_conv)\n",
    "        tf.summary.histogram('b_conv', b_conv)\n",
    "    \n",
    "    return h_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.06\n",
      "step 100, training accuracy 0.42\n",
      "step 200, training accuracy 0.52\n",
      "step 300, training accuracy 0.62\n",
      "step 400, training accuracy 0.66\n",
      "step 500, training accuracy 0.8\n",
      "step 600, training accuracy 0.84\n",
      "step 700, training accuracy 0.7\n",
      "step 800, training accuracy 0.9\n",
      "step 900, training accuracy 0.82\n",
      "step 1000, training accuracy 0.9\n",
      "step 1100, training accuracy 0.78\n",
      "step 1200, training accuracy 0.86\n",
      "step 1300, training accuracy 0.96\n",
      "step 1400, training accuracy 0.92\n",
      "step 1500, training accuracy 0.9\n",
      "step 1600, training accuracy 0.94\n",
      "step 1700, training accuracy 0.84\n",
      "step 1800, training accuracy 0.92\n",
      "step 1900, training accuracy 0.86\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default() as g:\n",
    "    with tf.name_scope('inputs'):\n",
    "        x = tf.placeholder(tf.float32, [None, 784])\n",
    "        y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "        x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "    conv1 = add_conv_layer(x_image, [5, 5], 1, 32)\n",
    "\n",
    "    with tf.name_scope('Image_output_conv1'):\n",
    "        conv1_image = conv1[0:1, :, :, 0:32]\n",
    "        conv1_image = tf.transpose(conv1_image, perm=[3,1,2,0])\n",
    "        tf.summary.image('Image_output_conv1', conv1_image, max_outputs=32)\n",
    "        \n",
    "    conv2 = add_conv_layer(conv1, [5, 5], 32, 64)\n",
    "    \n",
    "    with tf.name_scope('Image_output_conv2'):\n",
    "        conv2_image = conv2[0:1, :, :, 0:64]\n",
    "        conv2_image = tf.transpose(conv2_image, perm=[3,1,2,0])\n",
    "        tf.summary.image('Image_output_conv2', conv2_image, max_outputs=64)\n",
    "    \n",
    "    conv2_flat = tf.reshape(conv2, [-1, 7*7*64])\n",
    "    h_fc1 = add_fc_layer(conv2_flat, 7*7*64, 1024, tf.nn.relu)\n",
    "    \n",
    "    with tf.name_scope('dropout'):\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "        tf.summary.scalar('dropout_keep_probability', keep_prob)\n",
    "    \n",
    "    y_conv = add_fc_layer(h_fc1_drop, 1024, 10, tf.nn.softmax)\n",
    "    \n",
    "    # 损失函数\n",
    "    with tf.name_scope('loss'):\n",
    "        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_, logits=y_conv))\n",
    "\n",
    "    tf.summary.scalar('loss', cross_entropy)\n",
    "\n",
    "    with tf.name_scope('train'):\n",
    "        train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "    merged = tf.summary.merge_all()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        writer = tf.summary.FileWriter('./logs/conv', sess.graph)\n",
    "\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        for i in range(2000):\n",
    "            batch = mnist.train.next_batch(50)\n",
    "\n",
    "            if i%100 == 0:\n",
    "                train_accuracy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "                print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "\n",
    "            summary, _ = sess.run([merged, train_step], feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            writer.add_summary(summary, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
