{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 优化算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow提供了多种优化算法:\n",
    "- tf.train.GradientDescentOptimizer\n",
    "- tf.train.AdadeltaOptimizer\n",
    "- tf.train.AdagradOptimizer\n",
    "- tf.train.AdagradDAOptimizer\n",
    "- tf.train.MomentumOptimizer\n",
    "- tf.train.AdamOptimizer\n",
    "- tf.train.FtrlOptimizer\n",
    "- tf.train.ProximalGradientDescentOptimizer\n",
    "- tf.train.ProximalAdagradOptimizer\n",
    "- tf.train.RMSPropOptimizer\n",
    "\n",
    "参考：https://www.tensorflow.org/api_guides/python/train#Optimizers\n",
    "\n",
    "其中AdamOptimizer用的较多，其中使用方法如下：\n",
    "```\n",
    "# cross_entropy是损失函数\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)\n",
    "```\n",
    "详细API描述，请参考：https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**练习**: 请将下列代码的优化器更换成`AdamOptimizer`，并通过TensorBoard查看准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "0.0892\n",
      "0.0879\n",
      "0.0876\n",
      "0.0884\n",
      "0.1222\n",
      "0.1467\n",
      "0.1998\n",
      "0.4163\n",
      "0.5933\n",
      "0.6245\n",
      "0.6468\n",
      "0.6579\n",
      "0.6722\n",
      "0.6787\n",
      "0.7095\n",
      "0.7588\n",
      "0.775\n",
      "0.7849\n",
      "0.793\n",
      "0.7989\n",
      "0.8062\n",
      "0.8095\n",
      "0.815\n",
      "0.8197\n",
      "0.821\n",
      "0.8273\n",
      "0.8296\n",
      "0.8339\n",
      "0.8376\n",
      "0.8434\n",
      "0.8442\n",
      "0.8481\n",
      "0.8509\n",
      "0.8537\n",
      "0.8575\n",
      "0.8592\n",
      "0.8621\n",
      "0.8634\n",
      "0.8666\n",
      "0.8676\n",
      "0.8719\n",
      "0.8715\n",
      "0.8737\n",
      "0.8748\n",
      "0.876\n",
      "0.8778\n",
      "0.8784\n",
      "0.8788\n",
      "0.8808\n",
      "0.8817\n",
      "0.8814\n",
      "0.8832\n",
      "0.8858\n",
      "0.887\n",
      "0.8866\n",
      "0.8888\n",
      "0.891\n",
      "0.8904\n",
      "0.8914\n",
      "0.8905\n",
      "0.8928\n",
      "0.8939\n",
      "0.8949\n",
      "0.8948\n",
      "0.8954\n",
      "0.8957\n",
      "0.8949\n",
      "0.8968\n",
      "0.898\n",
      "0.8981\n",
      "0.8978\n",
      "0.8984\n",
      "0.8995\n",
      "0.8998\n",
      "0.8991\n",
      "0.9002\n",
      "0.9007\n",
      "0.9019\n",
      "0.9031\n",
      "0.9035\n",
      "0.9022\n",
      "0.9025\n",
      "0.9028\n",
      "0.903\n",
      "0.904\n",
      "0.9049\n",
      "0.9048\n",
      "0.9058\n",
      "0.9048\n",
      "0.9045\n",
      "0.9062\n",
      "0.9059\n",
      "0.9074\n",
      "0.9074\n",
      "0.9075\n",
      "0.9094\n",
      "0.9084\n",
      "0.9099\n",
      "0.9094\n",
      "0.9095\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 导入数据\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    # add one more layer and return the output of this layer\n",
    "    with tf.name_scope('layer'):\n",
    "        with tf.name_scope('weights'):\n",
    "            Weights = tf.Variable(tf.truncated_normal([in_size, out_size]), name='W')\n",
    "            \n",
    "        with tf.name_scope('biases'):\n",
    "            biases = tf.Variable(tf.constant(0.1, shape=[1, out_size]), name='b')\n",
    "            \n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            Wx_plus_b = tf.add(tf.matmul(inputs, Weights), biases)\n",
    "            \n",
    "        if activation_function is None:\n",
    "            outputs = Wx_plus_b\n",
    "        else:\n",
    "            outputs = activation_function(Wx_plus_b, )\n",
    "    \n",
    "    tf.summary.histogram('weights', Weights)\n",
    "    tf.summary.histogram('biases', biases)\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "with tf.Graph().as_default() as g:\n",
    "    with tf.name_scope('input'):\n",
    "        # X: 输入\n",
    "        X = tf.placeholder(tf.float32, [None, 784], name=\"X\")\n",
    "        # Y_: 标签\n",
    "        Y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "    # L1：200个神经元\n",
    "    Y1 = add_layer(X, 784, 200, tf.nn.sigmoid)\n",
    "\n",
    "    # L2：100个神经元\n",
    "    Y2 = add_layer(Y1, 200, 100, tf.nn.sigmoid)\n",
    "\n",
    "    # L3: 60个神经元\n",
    "    Y3 = add_layer(Y2, 100, 60, tf.nn.sigmoid)\n",
    "\n",
    "    # L4: 30个神经元\n",
    "    Y4 = add_layer(Y3, 60, 30, tf.nn.sigmoid)\n",
    "\n",
    "    # L5: 10个神经元\n",
    "    Ylogits = add_layer(Y4, 30, 10, tf.nn.sigmoid)\n",
    "\n",
    "    # Output\n",
    "    Y = tf.nn.softmax(Ylogits)\n",
    "\n",
    "    # 损失函数\n",
    "    with tf.name_scope('loss'):\n",
    "        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y_, logits=Ylogits))\n",
    "        \n",
    "    tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "        \n",
    "    # 优化算法\n",
    "    with tf.name_scope('train'):\n",
    "        train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "        \n",
    "    # 计算准确率\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    \n",
    "    merged = tf.summary.merge_all()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        # 将当前会话中的计算图保存\n",
    "        writer = tf.summary.FileWriter(\"logs/\", sess.graph)\n",
    "\n",
    "        for i in range(10000):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "            summary, _ = sess.run([merged, train_step], feed_dict={X: batch_xs, Y_: batch_ys})\n",
    "\n",
    "            writer.add_summary(summary, i)\n",
    "            \n",
    "            if i%100 == 0:\n",
    "                print(accuracy.eval({X: mnist.test.images, Y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Hyperparameter-学习速率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在机器学习的上下文中，超参数是在开始学习过程之前设置值的参数，而不是通过训练得到的参数数据。通常情况下，需要对超参数进行优化，给学习机选择一组最优超参数，以提高学习的性能和效果。例如在我们的MNIST任务中，AdamOptimizer的学习速率参数就是一个待确定的值。\n",
    "\n",
    "为了更好的比较不同超参数下模型的性能，一种比较简单的的方法就是得到各个参数下模型的性能，然后进行对比。TensorBoard支持同时显示不同超参数下的数据，只需要将不同参数下产生的TensorBoard数据写入到不同的子目录即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是一个很简单的例子，实现了$y=x+step$的功能，将不同的step的数据写入到`logs`的不同子目录下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lyon/.pyenv/versions/3.6.4/envs/scikit-learn/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "for step in [k for k in range(10)]:\n",
    "    with tf.Graph().as_default() as g:\n",
    "        x = tf.placeholder(tf.float32, shape=(), name='x')\n",
    "        y = x+step\n",
    "        tf.summary.scalar('y', y)\n",
    "\n",
    "        merged = tf.summary.merge_all()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            writer = tf.summary.FileWriter('logs/step_{0}/'.format(step))\n",
    "\n",
    "            for i in range(100):\n",
    "                summary, _ = sess.run([merged, y], feed_dict={x: i/100})\n",
    "\n",
    "                writer.add_summary(summary, i)\n",
    "\n",
    "                i += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**练习**: 根据上述代码，我们探索一下在不同学习速率下模型的性能变化。输出的日志文件保存在`logs/adm_lr_{value}/`子目录下，其中`value`是具体的学习速率值。例如lr=0.001，则对应的TensorFlow事件输出到`logs/lr_0.001`目录下 (提示，修改tf.summary.FileWriter的参数)。\n",
    "学习速率参数在`AdamOptimizer`中指定，其中学习速率取值从0.001开始，直到0.01，步长为0.001\n",
    "\n",
    "运行完成之后TensorBoard显示效果图如下：\n",
    "![image.png](http://p811pjpxl.bkt.clouddn.com/16-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lyon/.pyenv/versions/3.6.4/envs/scikit-learn/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-9d36dde7b959>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/lyon/.pyenv/versions/3.6.4/envs/scikit-learn/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/lyon/.pyenv/versions/3.6.4/envs/scikit-learn/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/lyon/.pyenv/versions/3.6.4/envs/scikit-learn/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/lyon/.pyenv/versions/3.6.4/envs/scikit-learn/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/lyon/.pyenv/versions/3.6.4/envs/scikit-learn/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "0.1414\n",
      "0.8695\n",
      "0.9122\n",
      "0.9173\n",
      "0.9263\n",
      "0.9369\n",
      "0.937\n",
      "0.94\n",
      "0.9432\n",
      "0.9348\n",
      "0.9453\n",
      "0.9277\n",
      "0.9431\n",
      "0.9399\n",
      "0.9454\n",
      "0.9412\n",
      "0.9507\n",
      "0.9482\n",
      "0.9462\n",
      "0.9449\n",
      "0.9453\n",
      "0.9518\n",
      "0.948\n",
      "0.9528\n",
      "0.9516\n",
      "0.952\n",
      "0.9489\n",
      "0.9521\n",
      "0.953\n",
      "0.9442\n",
      "0.9536\n",
      "0.9514\n",
      "0.9536\n",
      "0.9419\n",
      "0.9503\n",
      "0.9573\n",
      "0.9516\n",
      "0.9537\n",
      "0.9545\n",
      "0.9544\n",
      "0.9572\n",
      "0.9447\n",
      "0.9563\n",
      "0.9516\n",
      "0.9488\n",
      "0.9569\n",
      "0.9493\n",
      "0.9528\n",
      "0.9499\n",
      "0.9536\n",
      "0.9496\n",
      "0.9571\n",
      "0.9525\n",
      "0.9606\n",
      "0.9556\n",
      "0.9575\n",
      "0.9567\n",
      "0.9581\n",
      "0.9576\n",
      "0.9533\n",
      "0.9524\n",
      "0.9554\n",
      "0.9548\n",
      "0.9552\n",
      "0.9547\n",
      "0.958\n",
      "0.9602\n",
      "0.9555\n",
      "0.9617\n",
      "0.9588\n",
      "0.941\n",
      "0.9492\n",
      "0.9602\n",
      "0.9582\n",
      "0.9587\n",
      "0.9578\n",
      "0.9554\n",
      "0.9577\n",
      "0.9549\n",
      "0.9596\n",
      "0.9587\n",
      "0.9563\n",
      "0.9625\n",
      "0.9578\n",
      "0.9582\n",
      "0.956\n",
      "0.9578\n",
      "0.9563\n",
      "0.9544\n",
      "0.9443\n",
      "0.9541\n",
      "0.9592\n",
      "0.9593\n",
      "0.9511\n",
      "0.9598\n",
      "0.9572\n",
      "0.9549\n",
      "0.9514\n",
      "0.96\n",
      "0.9633\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 导入数据\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    # add one more layer and return the output of this layer\n",
    "    with tf.name_scope('layer'):\n",
    "        with tf.name_scope('weights'):\n",
    "            Weights = tf.Variable(tf.truncated_normal([in_size, out_size]), name='W')\n",
    "            \n",
    "        with tf.name_scope('biases'):\n",
    "            biases = tf.Variable(tf.constant(0.1, shape=[1, out_size]), name='b')\n",
    "            \n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            Wx_plus_b = tf.add(tf.matmul(inputs, Weights), biases)\n",
    "            \n",
    "        if activation_function is None:\n",
    "            outputs = Wx_plus_b\n",
    "        else:\n",
    "            outputs = activation_function(Wx_plus_b, )\n",
    "    \n",
    "    tf.summary.histogram('weights', Weights)\n",
    "    tf.summary.histogram('biases', biases)\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "with tf.Graph().as_default() as g:\n",
    "    with tf.name_scope('input'):\n",
    "        # X: 输入\n",
    "        X = tf.placeholder(tf.float32, [None, 784], name=\"X\")\n",
    "        # Y_: 标签\n",
    "        Y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "    # L1：200个神经元\n",
    "    Y1 = add_layer(X, 784, 200, tf.nn.sigmoid)\n",
    "\n",
    "    # L2：100个神经元\n",
    "    Y2 = add_layer(Y1, 200, 100, tf.nn.sigmoid)\n",
    "\n",
    "    # L3: 60个神经元\n",
    "    Y3 = add_layer(Y2, 100, 60, tf.nn.sigmoid)\n",
    "\n",
    "    # L4: 30个神经元\n",
    "    Y4 = add_layer(Y3, 60, 30, tf.nn.sigmoid)\n",
    "\n",
    "    # L5: 10个神经元\n",
    "    Ylogits = add_layer(Y4, 30, 10, tf.nn.sigmoid)\n",
    "\n",
    "    # Output\n",
    "    Y = tf.nn.softmax(Ylogits)\n",
    "\n",
    "    # 损失函数\n",
    "    with tf.name_scope('loss'):\n",
    "        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y_, logits=Ylogits))\n",
    "        \n",
    "    tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "        \n",
    "    # 优化算法\n",
    "    with tf.name_scope('train'):\n",
    "        train_step = tf.train.AdamOptimizer(0.01).minimize(cross_entropy)\n",
    "        \n",
    "    # 计算准确率\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    \n",
    "    merged = tf.summary.merge_all()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        # 将当前会话中的计算图保存\n",
    "        writer = tf.summary.FileWriter(\"logs/\", sess.graph)\n",
    "\n",
    "        for i in range(10000):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "            summary, _ = sess.run([merged, train_step], feed_dict={X: batch_xs, Y_: batch_ys})\n",
    "\n",
    "            writer.add_summary(summary, i)\n",
    "            \n",
    "            if i%100 == 0:\n",
    "                print(accuracy.eval({X: mnist.test.images, Y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 对比不同算法的性能 (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**练习**: 对比`GradientDescentOptimizer`和`tf.train.AdamOptimizer`的性能区别。\n",
    "提示：使用GradientDescentOptimizer算法，学习速率从0.1开始一直到1.0，输出到子目录`logs/gd_lr_{value}`下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 本地安装TF环境"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先安装Python 3的环境，然后通过pip进行安装\n",
    "```\n",
    "pip install tensorflow\n",
    "pip install jupyter\n",
    "```\n",
    "\n",
    "安装完成后，启动jupyter服务端：\n",
    "```\n",
    "jupyter notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
