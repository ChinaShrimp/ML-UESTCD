{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 回顾TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 启动\n",
    "登陆虚拟机，运行以下命令启动TensorBoard:\n",
    "```\n",
    "docker exec -it datalab /bin/sh\n",
    "tensorboard -logdir /content  (将/content替换成具体日志的路径)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 节点名称(node name)和命名空间(name scope)\n",
    "为了让计算图显示的更加有序，在编写TensorFlow代码时应该正确的使用。\n",
    "\n",
    "计算图中的每个节点都需要有名称，可以使用`name`参数进行定义：\n",
    "```\n",
    "Weights = tf.Variable(..., name='W')\n",
    "```\n",
    "\n",
    "需要将每个节点放置在合适的命名空间内：\n",
    "\n",
    "```\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = tf.reduce_mean(tf.reduce_sum(...))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 计算图\n",
    "\n",
    "通过`tf.Graph()`创建新的计算图，并将相应的节点都放入该计算图中：\n",
    "```\n",
    "with tf.Graph().as_default() as g:\n",
    "    with tf.name_scope('inputs'):\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 TensorBoard参考\n",
    "1. TensorFlow 2017 Dev Summit (TensorBoard): https://github.com/mamcgrath/TensorBoard-TF-Dev-Summit-Tutorial/blob/master/slides.pdf\n",
    "2. TensorBoard官网参考资料： https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard?hl=zh-cn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 重新开始\n",
    "以下是上次的作业，进行重构后的FFNN代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lyon/.pyenv/versions/3.6.4/envs/scikit-learn/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-48c72de3fe49>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/lyon/.pyenv/versions/3.6.4/envs/scikit-learn/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/lyon/.pyenv/versions/3.6.4/envs/scikit-learn/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/lyon/.pyenv/versions/3.6.4/envs/scikit-learn/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/lyon/.pyenv/versions/3.6.4/envs/scikit-learn/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/lyon/.pyenv/versions/3.6.4/envs/scikit-learn/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "0.0982\n",
      "0.1135\n",
      "0.1135\n",
      "0.1135\n",
      "0.1135\n",
      "0.1135\n",
      "0.101\n",
      "0.1135\n",
      "0.1135\n",
      "0.1135\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 导入数据\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    # add one more layer and return the output of this layer\n",
    "    with tf.name_scope('layer'):\n",
    "        with tf.name_scope('weights'):\n",
    "            Weights = tf.Variable(tf.zeros([in_size, out_size]), name='W')\n",
    "            \n",
    "        with tf.name_scope('biases'):\n",
    "            biases = tf.Variable(tf.zeros([1, out_size]), name='b')\n",
    "            \n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            Wx_plus_b = tf.add(tf.matmul(inputs, Weights), biases)\n",
    "            \n",
    "        if activation_function is None:\n",
    "            outputs = Wx_plus_b\n",
    "        else:\n",
    "            outputs = activation_function(Wx_plus_b, )\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "with tf.Graph().as_default() as g:\n",
    "    with tf.name_scope('input'):\n",
    "        # X: 输入\n",
    "        X = tf.placeholder(tf.float32, [None, 784], name=\"X\")\n",
    "        # Y_: 标签\n",
    "        Y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "    # L1：200个神经元\n",
    "    Y1 = add_layer(X, 784, 200, tf.nn.sigmoid)\n",
    "\n",
    "    # L2：100个神经元\n",
    "    Y2 = add_layer(Y1, 200, 100, tf.nn.sigmoid)\n",
    "\n",
    "    # L3: 60个神经元\n",
    "    Y3 = add_layer(Y2, 100, 60, tf.nn.sigmoid)\n",
    "\n",
    "    # L4: 30个神经元\n",
    "    Y4 = add_layer(Y3, 60, 30, tf.nn.sigmoid)\n",
    "\n",
    "    # L5: 10个神经元\n",
    "    Ylogits = add_layer(Y4, 30, 10, tf.nn.sigmoid)\n",
    "\n",
    "    # Output\n",
    "    Y = tf.nn.softmax(Ylogits)\n",
    "\n",
    "    # 损失函数\n",
    "    with tf.name_scope('loss'):\n",
    "        cross_entropy = tf.reduce_mean(-tf.reduce_sum(Y_ * tf.log(Y), reduction_indices=[1]))\n",
    "        \n",
    "\n",
    "    # 优化算法\n",
    "    with tf.name_scope('train'):\n",
    "        train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "        \n",
    "    # 计算准确率\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        # 将当前会话中的计算图保存\n",
    "        writer = tf.summary.FileWriter(\"logs/\", sess.graph)\n",
    "\n",
    "        for i in range(1000):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "            _ = sess.run([train_step], feed_dict={X: batch_xs, Y_: batch_ys})\n",
    "\n",
    "            if i%100 == 0:\n",
    "                print(accuracy.eval({X: mnist.test.images, Y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行上述代码后，发现准确率一直在10%，我们需要更多的信息去诊断问题！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Scalar数据\n",
    "TensorBoard 通过读取 TensorFlow 的事件文件来运行。TensorFlow 的事件文件包含运行 TensorFlow 时生成的总结数据。下面是 TensorBoard 中总结数据的一般生命周期。\n",
    "\n",
    "1. 创建您想从中收集总结数据的 TensorFlow 图，然后再选择您想在哪个节点标注总结指令(summary)。假设您正在训练一个神经网络，用于识别 MNIST 数据。您可能希望记录随着时间的推移，学习速度如何变化，以及目标函数如何变化。通过向节点附加 tf.summary.scalar op 来分别输出学习速度和误差。例如：\n",
    "```\n",
    "    # 损失函数\n",
    "    with tf.name_scope('loss'):\n",
    "        cross_entropy = tf.reduce_mean(-tf.reduce_sum(Y_ * tf.log(Y), reduction_indices=[1]))\n",
    "        \n",
    "    # 输出损失函数的值(类型：标量)\n",
    "    tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "    \n",
    "    ...\n",
    "    # 计算准确率\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "    # 输出损失函数的值(类型：标量)\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "```\n",
    "有关所有可用的总结指令的详细信息，可查看：https://www.tensorflow.org/api_guides/python/summary?hl=zh-cn\n",
    "\n",
    "2. 在 TensorFlow 中，只有当您运行指令时，指令才会执行，或者另一个 op 依赖于指令的输出时，指令才会运行。我们刚才创建的这些总结节点都围绕着您的图：您目前运行的 op 都不依赖于这些节点的结果。因此，为了生成总结信息，我们需要运行所有这些总结节点。这样的手动操作是枯燥而乏味的，因此可以使用 tf.summary.merge_all 来将这些操作合并为一个 op，从而生成所有总结数据。\n",
    "```\n",
    "    # 实际使用中会输出多个信息，惯用做法是将所有输出打包\n",
    "    merged = tf.summary.merge_all()\n",
    "```\n",
    "\n",
    "3. 您可以执行该合并的总结 op，它会在特定步骤将所有总结数据生成一个序列化的 Summary protobuf 对象。最后，如要将此总结数据写入磁盘，请将此总结 protobuf 对象传递给 tf.summary.FileWriter。FileWriter 的构造函数中包含了参数 logdir，logdir 参数非常重要，所有事件都会写到它所指的目录下。**注意：输出运行时的概要信息(summary)是在会话运行的时候进行的**\n",
    "```\n",
    "with tf.Session() as sess:\n",
    "    ...\n",
    "    summary, _ = sess.run([merged, train_step], feed_dict={X: batch_xs, Y_: batch_ys})\n",
    "\n",
    "    for i in range(1000):\n",
    "        ...\n",
    "        # 将每次迭代过程中的信息，通过FileWriter输出\n",
    "        writer.add_summary(summary, i)\n",
    "        ...\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "练习：将上述添加概要信息的代码，添加到下面代码块合适的位置，运行TensorBoard查看输出信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "0.0958\n",
      "0.1135\n",
      "0.1135\n",
      "0.1135\n",
      "0.1135\n",
      "0.1135\n",
      "0.1135\n",
      "0.1135\n",
      "0.1135\n",
      "0.1135\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 导入数据\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "with tf.Graph().as_default() as g:\n",
    "    with tf.name_scope('input'):\n",
    "        # X: 输入\n",
    "        X = tf.placeholder(tf.float32, [None, 784], name=\"X\")\n",
    "        # Y_: 标签\n",
    "        Y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "    # L1：200个神经元\n",
    "    Y1 = add_layer(X, 784, 200, tf.nn.sigmoid)\n",
    "\n",
    "    # L2：100个神经元\n",
    "    Y2 = add_layer(Y1, 200, 100, tf.nn.sigmoid)\n",
    "\n",
    "    # L3: 60个神经元\n",
    "    Y3 = add_layer(Y2, 100, 60, tf.nn.sigmoid)\n",
    "\n",
    "    # L4: 30个神经元\n",
    "    Y4 = add_layer(Y3, 60, 30, tf.nn.sigmoid)\n",
    "\n",
    "    # L5: 10个神经元\n",
    "    Ylogits = add_layer(Y4, 30, 10, tf.nn.sigmoid)\n",
    "\n",
    "    # Output\n",
    "    Y = tf.nn.softmax(Ylogits)\n",
    "\n",
    "    # 损失函数\n",
    "    with tf.name_scope('loss'):\n",
    "        cross_entropy = tf.reduce_mean(-tf.reduce_sum(Y_ * tf.log(Y), reduction_indices=[1]))\n",
    "    \n",
    "    tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "    \n",
    "    # 优化算法\n",
    "    with tf.name_scope('train'):\n",
    "        train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "        \n",
    "    # 计算准确率\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    \n",
    "    merged = tf.summary.merge_all()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        # 将当前会话中的计算图保存\n",
    "        writer = tf.summary.FileWriter(\"logs/\", sess.graph)\n",
    "\n",
    "        for i in range(1000):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "            summary, _ = sess.run([merged, train_step], feed_dict={X: batch_xs, Y_: batch_ys})\n",
    "            \n",
    "            writer.add_summary(summary, i)\n",
    "            \n",
    "            if i%100 == 0:\n",
    "                print(accuracy.eval({X: mnist.test.images, Y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 模型参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经过2.1的努力，我们看到了迭代过程中损失函数和准确率的变化，如下图所示：\n",
    "![损失函数和准确率](http://p811pjpxl.bkt.clouddn.com/15-1.png)\n",
    "\n",
    "从上述图表中我们发现，损失函数的值在训练过程中并没有明显下降。我们需要可视化更多的数据，下一步我们要将W(Weights)和B(Biases)进行可视化，使用`tf.summary.histogram`。\n",
    "\n",
    "```\n",
    "    tf.summary.histogram('weights', Weights)\n",
    "    tf.summary.histogram('biases', biases)\n",
    "```\n",
    "\n",
    "API参考：https://www.tensorflow.org/api_docs/python/tf/summary/histogram?hl=zh-cn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**练习**：\n",
    "```\n",
    "    tf.summary.histogram('weights', Weights)\n",
    "    tf.summary.histogram('biases', biases)\n",
    "```\n",
    "将上述代码添加到下列代码块合适的地方，输出神经网络中的参数Weights和biases。通过TensorBoard查看相应的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "0.1135\n",
      "0.1135\n",
      "0.1135\n",
      "0.1028\n",
      "0.1135\n",
      "0.1135\n",
      "0.1135\n",
      "0.1135\n",
      "0.1135\n",
      "0.1135\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 导入数据\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    # add one more layer and return the output of this layer\n",
    "    with tf.name_scope('layer'):\n",
    "        with tf.name_scope('weights'):\n",
    "            Weights = tf.Variable(tf.zeros([in_size, out_size]), name='W')\n",
    "            \n",
    "        with tf.name_scope('biases'):\n",
    "            biases = tf.Variable(tf.zeros([1, out_size]), name='b')\n",
    "            \n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            Wx_plus_b = tf.add(tf.matmul(inputs, Weights), biases)\n",
    "            \n",
    "        tf.summary.histogram('weights', Weights)\n",
    "        tf.summary.histogram('biases', biases)\n",
    "        \n",
    "            \n",
    "        if activation_function is None:\n",
    "            outputs = Wx_plus_b\n",
    "        else:\n",
    "            outputs = activation_function(Wx_plus_b, )\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "with tf.Graph().as_default() as g:\n",
    "    with tf.name_scope('input'):\n",
    "        # X: 输入\n",
    "        X = tf.placeholder(tf.float32, [None, 784], name=\"X\")\n",
    "        # Y_: 标签\n",
    "        Y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "    # L1：200个神经元\n",
    "    Y1 = add_layer(X, 784, 200, tf.nn.sigmoid)\n",
    "\n",
    "    # L2：100个神经元\n",
    "    Y2 = add_layer(Y1, 200, 100, tf.nn.sigmoid)\n",
    "\n",
    "    # L3: 60个神经元\n",
    "    Y3 = add_layer(Y2, 100, 60, tf.nn.sigmoid)\n",
    "\n",
    "    # L4: 30个神经元\n",
    "    Y4 = add_layer(Y3, 60, 30, tf.nn.sigmoid)\n",
    "\n",
    "    # L5: 10个神经元\n",
    "    Ylogits = add_layer(Y4, 30, 10, tf.nn.sigmoid)\n",
    "\n",
    "    # Output\n",
    "    Y = tf.nn.softmax(Ylogits)\n",
    "\n",
    "    # 损失函数\n",
    "    with tf.name_scope('loss'):\n",
    "        cross_entropy = tf.reduce_mean(-tf.reduce_sum(Y_ * tf.log(Y), reduction_indices=[1]))\n",
    "        \n",
    "    tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "        \n",
    "    # 优化算法\n",
    "    with tf.name_scope('train'):\n",
    "        train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "        \n",
    "    # 计算准确率\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    \n",
    "    merged = tf.summary.merge_all()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        # 将当前会话中的计算图保存\n",
    "        writer = tf.summary.FileWriter(\"logs/\", sess.graph)\n",
    "\n",
    "        for i in range(1000):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "            summary, _ = sess.run([merged, train_step], feed_dict={X: batch_xs, Y_: batch_ys})\n",
    "\n",
    "            writer.add_summary(summary, i)\n",
    "            \n",
    "            if i%100 == 0:\n",
    "                print(accuracy.eval({X: mnist.test.images, Y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 初始化参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过可视化Weights和biases的值，我们发现他们都在0徘徊，好像'根本没有学习到任何有用的经验'! 问题主要出在，我们的代码将他们都初始化为0！！！\n",
    "\n",
    "TensorFlow提供了如下方法对于变量进行初始化：\n",
    "![初始化方法](http://p811pjpxl.bkt.clouddn.com/15-2.png)\n",
    "\n",
    "我们需要选用上图中合适的方法对网络模型中的Weights和biases参数进行初始化。\n",
    "例如将Weights初始化为随机值(符合正态分布)：\n",
    "```\n",
    "Weights = tf.Variable(tf.truncated_normal([in_size, out_size]), name='W')\n",
    "```\n",
    "例如将biases初始化为0.1:\n",
    "```\n",
    "biases = tf.Variable(tf.constant(0.1, shape=[1, out_size]), name='b')\n",
    "```\n",
    "\n",
    "参考：\n",
    "- `tf.constant`:\n",
    "https://www.tensorflow.org/api_docs/python/tf/constant?hl=zh-cn\n",
    "\n",
    "- `tf.truncated_normal:`\n",
    "https://www.tensorflow.org/versions/master/api_docs/python/tf/truncated_normal?hl=zh-cn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "练习：修改函数`add_layer`中变量的初始化代码，并运行。通过TensorBoard查看损失函数`cross_entropy`的变化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "0.098\n",
      "0.1135\n",
      "0.1135\n",
      "0.1135\n",
      "0.1135\n",
      "0.1135\n",
      "0.1028\n",
      "0.1135\n",
      "0.1028\n",
      "0.1135\n",
      "0.1135\n",
      "0.1135\n",
      "0.1135\n",
      "0.1135\n",
      "0.1135\n",
      "0.1135\n",
      "0.1135\n",
      "0.1135\n",
      "0.1135\n",
      "0.1135\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 导入数据\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    # add one more layer and return the output of this layer\n",
    "    with tf.name_scope('layer'):\n",
    "        with tf.name_scope('weights'):\n",
    "            Weights = tf.Variable(tf.zeros([in_size, out_size]), name='W')\n",
    "            \n",
    "        with tf.name_scope('biases'):\n",
    "            biases = tf.Variable(tf.zeros(shape=[1, out_size]), name='b')\n",
    "            \n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            Wx_plus_b = tf.add(tf.matmul(inputs, Weights), biases)\n",
    "            \n",
    "        if activation_function is None:\n",
    "            outputs = Wx_plus_b\n",
    "        else:\n",
    "            outputs = activation_function(Wx_plus_b, )\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "with tf.Graph().as_default() as g:\n",
    "    with tf.name_scope('input'):\n",
    "        # X: 输入\n",
    "        X = tf.placeholder(tf.float32, [None, 784], name=\"X\")\n",
    "        # Y_: 标签\n",
    "        Y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "    # L1：200个神经元\n",
    "    Y1 = add_layer(X, 784, 200, tf.nn.sigmoid)\n",
    "\n",
    "    # L2：100个神经元\n",
    "    Y2 = add_layer(Y1, 200, 100, tf.nn.sigmoid)\n",
    "\n",
    "    # L3: 60个神经元\n",
    "    Y3 = add_layer(Y2, 100, 60, tf.nn.sigmoid)\n",
    "\n",
    "    # L4: 30个神经元\n",
    "    Y4 = add_layer(Y3, 60, 30, tf.nn.sigmoid)\n",
    "\n",
    "    # L5: 10个神经元\n",
    "    Ylogits = add_layer(Y4, 30, 10, tf.nn.sigmoid)\n",
    "\n",
    "    # Output\n",
    "    Y = tf.nn.softmax(Ylogits)\n",
    "\n",
    "    # 损失函数\n",
    "    with tf.name_scope('loss'):\n",
    "        cross_entropy = tf.reduce_mean(-tf.reduce_sum(Y_ * tf.log(Y), reduction_indices=[1]))\n",
    "        \n",
    "    tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "        \n",
    "    # 优化算法\n",
    "    with tf.name_scope('train'):\n",
    "        train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "        \n",
    "    # 计算准确率\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    \n",
    "    merged = tf.summary.merge_all()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        # 将当前会话中的计算图保存\n",
    "        writer = tf.summary.FileWriter(\"logs/\", sess.graph)\n",
    "\n",
    "        for i in range(1000):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "            summary, _ = sess.run([merged, train_step], feed_dict={X: batch_xs, Y_: batch_ys})\n",
    "\n",
    "            writer.add_summary(summary, i)\n",
    "            \n",
    "            if i%100 == 0:\n",
    "                print(accuracy.eval({X: mnist.test.images, Y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 迭代次数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看运行2.3程序后的损失函数图，发现损失函数呈下降趋势，但是并未收敛，说明训练并未完成，需要增加训练次数。\n",
    "![image.png](http://p811pjpxl.bkt.clouddn.com/15-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**练习**：修改训练迭代次数，直到通过TensorBoard查看到损失函数值收敛。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "0.1008\n",
      "0.1009\n",
      "0.1009\n",
      "0.1009\n",
      "0.1009\n",
      "0.1009\n",
      "0.1009\n",
      "0.1009\n",
      "0.1009\n",
      "0.1009\n",
      "0.1009\n",
      "0.1009\n",
      "0.1009\n",
      "0.1009\n",
      "0.1009\n",
      "0.1009\n",
      "0.1009\n",
      "0.1009\n",
      "0.1015\n",
      "0.1019\n",
      "0.1021\n",
      "0.1021\n",
      "0.1026\n",
      "0.1033\n",
      "0.1042\n",
      "0.1142\n",
      "0.1239\n",
      "0.1335\n",
      "0.1401\n",
      "0.1439\n",
      "0.1612\n",
      "0.1873\n",
      "0.1966\n",
      "0.2531\n",
      "0.2798\n",
      "0.3467\n",
      "0.4451\n",
      "0.5809\n",
      "0.7575\n",
      "0.83\n",
      "0.8441\n",
      "0.8478\n",
      "0.8512\n",
      "0.8532\n",
      "0.8557\n",
      "0.859\n",
      "0.8619\n",
      "0.8619\n",
      "0.8658\n",
      "0.867\n",
      "0.8685\n",
      "0.8716\n",
      "0.8726\n",
      "0.8734\n",
      "0.8741\n",
      "0.877\n",
      "0.8782\n",
      "0.8804\n",
      "0.8817\n",
      "0.8821\n",
      "0.8842\n",
      "0.8838\n",
      "0.8862\n",
      "0.8878\n",
      "0.8885\n",
      "0.8887\n",
      "0.8893\n",
      "0.8907\n",
      "0.8918\n",
      "0.8916\n",
      "0.8934\n",
      "0.894\n",
      "0.8948\n",
      "0.8961\n",
      "0.8957\n",
      "0.8983\n",
      "0.9004\n",
      "0.8976\n",
      "0.9003\n",
      "0.9007\n",
      "0.8999\n",
      "0.9011\n",
      "0.9026\n",
      "0.9034\n",
      "0.9026\n",
      "0.9019\n",
      "0.9038\n",
      "0.9044\n",
      "0.9053\n",
      "0.9054\n",
      "0.9054\n",
      "0.9062\n",
      "0.9068\n",
      "0.9072\n",
      "0.9071\n",
      "0.9082\n",
      "0.9085\n",
      "0.9083\n",
      "0.9089\n",
      "0.9094\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 导入数据\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    # add one more layer and return the output of this layer\n",
    "    with tf.name_scope('layer'):\n",
    "        with tf.name_scope('weights'):\n",
    "            Weights = tf.Variable(tf.truncated_normal([in_size, out_size]), name='W')\n",
    "            \n",
    "        with tf.name_scope('biases'):\n",
    "            biases = tf.Variable(tf.constant(0.1, shape=[1, out_size]), name='b')\n",
    "            \n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            Wx_plus_b = tf.add(tf.matmul(inputs, Weights), biases)\n",
    "            \n",
    "        if activation_function is None:\n",
    "            outputs = Wx_plus_b\n",
    "        else:\n",
    "            outputs = activation_function(Wx_plus_b, )\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "with tf.Graph().as_default() as g:\n",
    "    with tf.name_scope('input'):\n",
    "        # X: 输入\n",
    "        X = tf.placeholder(tf.float32, [None, 784], name=\"X\")\n",
    "        # Y_: 标签\n",
    "        Y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "    # L1：200个神经元\n",
    "    Y1 = add_layer(X, 784, 200, tf.nn.sigmoid)\n",
    "\n",
    "    # L2：100个神经元\n",
    "    Y2 = add_layer(Y1, 200, 100, tf.nn.sigmoid)\n",
    "\n",
    "    # L3: 60个神经元\n",
    "    Y3 = add_layer(Y2, 100, 60, tf.nn.sigmoid)\n",
    "\n",
    "    # L4: 30个神经元\n",
    "    Y4 = add_layer(Y3, 60, 30, tf.nn.sigmoid)\n",
    "\n",
    "    # L5: 10个神经元\n",
    "    Ylogits = add_layer(Y4, 30, 10, tf.nn.sigmoid)\n",
    "\n",
    "    # Output\n",
    "    Y = tf.nn.softmax(Ylogits)\n",
    "\n",
    "    # 损失函数\n",
    "    with tf.name_scope('loss'):\n",
    "        cross_entropy = tf.reduce_mean(-tf.reduce_sum(Y_ * tf.log(Y), reduction_indices=[1]))\n",
    "        \n",
    "    tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "        \n",
    "    # 优化算法\n",
    "    with tf.name_scope('train'):\n",
    "        train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "        \n",
    "    # 计算准确率\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    \n",
    "    merged = tf.summary.merge_all()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        # 将当前会话中的计算图保存\n",
    "        writer = tf.summary.FileWriter(\"logs/\", sess.graph)\n",
    "\n",
    "        for i in range(10000):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "            summary, _ = sess.run([merged, train_step], feed_dict={X: batch_xs, Y_: batch_ys})\n",
    "\n",
    "            writer.add_summary(summary, i)\n",
    "            \n",
    "            if i%100 == 0:\n",
    "                print(accuracy.eval({X: mnist.test.images, Y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到通过增加训练迭代次数，训练效果得到明显提升：\n",
    "![image.png](http://p811pjpxl.bkt.clouddn.com/15-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考\n",
    "1. https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/4-1-tensorboard1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考答案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    # add one more layer and return the output of this layer\n",
    "    with tf.name_scope('layer'):\n",
    "        with tf.name_scope('weights'):\n",
    "            Weights = tf.Variable(tf.random_normal([in_size, out_size]), name='W')\n",
    "            \n",
    "        with tf.name_scope('biases'):\n",
    "            biases = tf.Variable(tf.zeros([1, out_size]) + 0.1, name='b')\n",
    "            \n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            Wx_plus_b = tf.add(tf.matmul(inputs, Weights), biases)\n",
    "            \n",
    "        if activation_function is None:\n",
    "            outputs = Wx_plus_b\n",
    "        else:\n",
    "            outputs = activation_function(Wx_plus_b, )\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "\n",
    "with tf.name_scope('inputs'):\n",
    "    # define placeholder for inputs to network\n",
    "    xs = tf.placeholder(tf.float32, [None, 1], name='x_input')\n",
    "    ys = tf.placeholder(tf.float32, [None, 1], name='y_input')\n",
    "\n",
    "# add hidden layer\n",
    "l1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)\n",
    "\n",
    "# add output layer\n",
    "prediction = add_layer(l1, 10, 1, activation_function=None)\n",
    "\n",
    "# the error between prediciton and real data\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),\n",
    "                                        reduction_indices=[1]))\n",
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # 将当前会话中的计算图保存\n",
    "    writer = tf.summary.FileWriter(\"logs/\", sess.graph)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    # add one more layer and return the output of this layer\n",
    "    with tf.name_scope('layer'):\n",
    "        with tf.name_scope('weights'):\n",
    "            Weights = tf.Variable(tf.random_normal([in_size, out_size]), name='W')\n",
    "            \n",
    "        with tf.name_scope('biases'):\n",
    "            biases = tf.Variable(tf.zeros([1, out_size]) + 0.1, name='b')\n",
    "            \n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            Wx_plus_b = tf.add(tf.matmul(inputs, Weights), biases)\n",
    "            \n",
    "        if activation_function is None:\n",
    "            outputs = Wx_plus_b\n",
    "        else:\n",
    "            outputs = activation_function(Wx_plus_b, )\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "\n",
    "with tf.Graph().as_default() as g:\n",
    "    with tf.name_scope('inputs'):\n",
    "        # define placeholder for inputs to network\n",
    "        xs = tf.placeholder(tf.float32, [None, 1], name='x_input')\n",
    "        ys = tf.placeholder(tf.float32, [None, 1], name='y_input')\n",
    "\n",
    "    # add hidden layer\n",
    "    l1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)\n",
    "\n",
    "    # add output layer\n",
    "    prediction = add_layer(l1, 10, 1, activation_function=None)\n",
    "\n",
    "    # the error between prediciton and real data\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),\n",
    "                                            reduction_indices=[1]))\n",
    "    with tf.name_scope('train'):\n",
    "        train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        # 将当前会话中的计算图保存\n",
    "        writer = tf.summary.FileWriter(\"logs/\", sess.graph)\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
